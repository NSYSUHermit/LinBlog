Non_Sampling = list[0.9994803480263759,0.8678545237199384],
Under_Sampling = list[0.9995084373222475,0.8901876266312907],
SMOTE = list[0.9994663033784401,0.9023405417267101],
ADASYN = list[0.9993890578147933,0.8982438459344533],
GAN = list[0.999557596696722,0.9003572630796582]
)
result <- data.frame(
Non_Sampling = list(0.9994803480263759,0.8678545237199384),
Under_Sampling = list(0.9995084373222475,0.8901876266312907),
SMOTE = list(0.9994663033784401,0.9023405417267101),
ADASYN = list(0.9993890578147933,0.8982438459344533),
GAN = list(0.999557596696722,0.9003572630796582)
)
View(result)
View(result)
result <- data.frame(
Non_Sampling = array(0.9994803480263759,0.8678545237199384),
Under_Sampling = array(0.9995084373222475,0.8901876266312907),
SMOTE = array(0.9994663033784401,0.9023405417267101),
ADASYN = array(0.9993890578147933,0.8982438459344533),
GAN = array(0.999557596696722,0.9003572630796582)
)
View(result)
GAN = array(0.999557596696722,0.9003572630796582)
GAN = vector(0.999557596696722,0.9003572630796582)
GAN = dataframe(0.999557596696722,0.9003572630796582)
GAN = data.frame(0.999557596696722,0.9003572630796582)
View(GAN)
result <- data.frame(
Non_Sampling = data.frame(0.9994803480263759,0.8678545237199384),
Under_Sampling = data.frame(0.9995084373222475,0.8901876266312907),
SMOTE = data.frame(0.9994663033784401,0.9023405417267101),
ADASYN = data.frame(0.9993890578147933,0.8982438459344533),
GAN = data.frame(0.999557596696722,0.9003572630796582)
)
View(result)
View(GAN)
View(result)
View(GAN)
result <- data.frame()
result$
View(GAN)
View(result)
result$Non_Sampling = data.frame(0.9994803480263759,0.8678545237199384)
result$Non_Sampling = vector(0.9994803480263759,0.8678545237199384)
result$Non_Sampling = float(0.9994803480263759,0.8678545237199384)
result$Non_Sampling = double(0.9994803480263759,0.8678545237199384)
result$Non_Sampling = [0.9994803480263759,0.8678545237199384]
result$Non_Sampling = c(0.9994803480263759,0.8678545237199384)
result$Non_Sampling = vector(c(0.9994803480263759,0.8678545237199384))
result$Non_Sampling = data.frame(c(0.9994803480263759,0.8678545237199384))
result = data.frame(c(0.9994803480263759,0.8678545237199384))
View(result)
result$Under_Sampling = data.frame(c(0.9995084373222475,0.8901876266312907))
View(result)
View(result)
result$SMOTE = data.frame(0.9994663033784401,0.9023405417267101)
result$ADASYN = data.frame(c(0.9993890578147933,0.8982438459344533))
result$GAN = data.frame(c(0.999557596696722,0.9003572630796582))
View(result)
result <- data.frame()
result <- data.frame()
result = data.frame(c(0.9994803480263759,0.8678545237199384))
result$Under_Sampling = data.frame(c(0.9995084373222475,0.8901876266312907))
result$SMOTE = data.frame(c(0.9994663033784401,0.9023405417267101))
result$ADASYN = data.frame(c(0.9993890578147933,0.8982438459344533))
result$GAN = data.frame(c(0.999557596696722,0.9003572630796582))
View(result)
colnames(result) <- c("Non Sampling","Under Sampling","SMOTE","ADASYN","GAN")
View(result)
colnames(result)
result <- data.frame()
colnames(result) <- c("Non Sampling","Under Sampling","SMOTE","ADASYN","GAN")
result <- data.frame()
result = data.frame(c(0.9994803480263759,0.8678545237199384))
result$Under_Sampling = data.frame(c(0.9995084373222475,0.8901876266312907))
result$SMOTE = data.frame(c(0.9994663033784401,0.9023405417267101))
result$ADASYN = data.frame(c(0.9993890578147933,0.8982438459344533))
result$GAN = data.frame(c(0.999557596696722,0.9003572630796582))
colnames(result) <- c("Non Sampling","Under Sampling","SMOTE","ADASYN","GAN")
View(result)
result <- data.frame()
result = data.frame(c(0.9994803480263759,0.8678545237199384))
result$Under_Sampling = data.frame(c(0.9995084373222475,0.8901876266312907))
result$SMOTE = data.frame(c(0.9994663033784401,0.9023405417267101))
result$ADASYN = data.frame(c(0.9993890578147933,0.8982438459344533))
result$GAN = data.frame(c(0.999557596696722,0.9003572630796582))
colnames(result) <- c("Non Sampling","Under Sampling","SMOTE","ADASYN","GAN")
rownames(result) <- c("ACC","AUC")
View(result)
result <- data.frame()
result = data.frame(c(0.9994803480263759,0.8678545237199384))
result$Under_Sampling = data.frame(c(0.9995084373222475,0.8901876266312907))
result$SMOTE = data.frame(c(0.9994663033784401,0.9023405417267101))
result$ADASYN = data.frame(c(0.9993890578147933,0.8982438459344533))
result$GAN = data.frame(c(0.999557596696722,0.9003572630796582))
result$index <- c("ACC","AUC")
colnames(result) <- c("Non Sampling","Under Sampling","SMOTE","ADASYN","GAN")
rownames(result) <- c("ACC","AUC")
View(result)
result <- data.frame()
result = data.frame(c(0.9994803480263759,0.8678545237199384))
result$Under_Sampling = data.frame(c(0.9995084373222475,0.8901876266312907))
result$SMOTE = data.frame(c(0.9994663033784401,0.9023405417267101))
result$ADASYN = data.frame(c(0.9993890578147933,0.8982438459344533))
result$GAN = data.frame(c(0.999557596696722,0.9003572630796582))
result$index <- c("ACC","AUC")
colnames(result) <- c("Non Sampling","Under Sampling","SMOTE","ADASYN","GAN","index")
rownames(result) <- c("ACC","AUC")
View(result)
library(tideverse)
library(tidyverse)
ggplot(data = result,mapping = aes(x = index))
result  = data.frame(t(result))
View(result)
result <- data.frame()
result = data.frame(c(0.9994803480263759,0.8678545237199384))
result$Under_Sampling = data.frame(c(0.9995084373222475,0.8901876266312907))
result$SMOTE = data.frame(c(0.9994663033784401,0.9023405417267101))
result$ADASYN = data.frame(c(0.9993890578147933,0.8982438459344533))
result$GAN = data.frame(c(0.999557596696722,0.9003572630796582))
colnames(result) <- c("Non Sampling","Under Sampling","SMOTE","ADASYN","GAN","index")
result <- data.frame()
result = data.frame(c(0.9994803480263759,0.8678545237199384))
result$Under_Sampling = data.frame(c(0.9995084373222475,0.8901876266312907))
result$SMOTE = data.frame(c(0.9994663033784401,0.9023405417267101))
result$ADASYN = data.frame(c(0.9993890578147933,0.8982438459344533))
result$GAN = data.frame(c(0.999557596696722,0.9003572630796582))
colnames(result) <- c("Non Sampling","Under Sampling","SMOTE","ADASYN","GAN")
rownames(result) <- c("ACC","AUC")
#result$index <- c("ACC","AUC")
result  = data.frame(t(result))
View(result)
View(result)
ggplot(data = result,mapping = aes(x = ACC)
ggplot(data = result,mapping = aes(x = ACC))
ggplot(data = result,mapping = aes(x = ACC))+
geom_freqploy(binwidth = 0.1)
library(ggplot2)
ggplot(data = result,mapping = aes(x = ACC))+
geom_freqploy(binwidth = 0.1)
library(ggplot2)
ggplot(data = result,mapping = aes(x = ACC))+
geom_freqpoly(binwidth = 0.1)
library(ggplot2)
ggplot(data = result,mapping = aes(x = ACC))+
geom_freqpoly()
library(ggplot2)
ggplot(data = result,mapping = aes(x = ACC,y = AUC))+
geom_freqpoly()
library(ggplot2)
ggplot(data = result)+
geom_fpoint(mapping = aes(x = ACC,y = AUC))
library(ggplot2)
ggplot(data = result)+
geom_point(mapping = aes(x = ACC,y = AUC))
ggplot(data = result)+
geom_point(mapping = aes(x = ACC,y = AUC,color = rownames))
ggplot(data = result)+
geom_point(mapping = aes(x = ACC,y = AUC,color = rownames(result)))
ggplot(data = result)+
geom_point(mapping = aes(x = ACC,y = AUC,color = rownames(result),shape=17))
library(ggplot2)
ggplot(data = result)+
geom_point(mapping = aes(x = ACC,y = AUC,color = rownames(result)),shape=17)
library(ggplot2)
ggplot(data = result)+
geom_point(mapping = aes(x = ACC,y = AUC,color = rownames(result)),size=17)
library(ggplot2)
ggplot(data = result)+
geom_point(mapping = aes(x = ACC,y = AUC,color = rownames(result)),size=7)
result <- data.frame()
result = data.frame(c(0.9994803480263759,0.8678545237199384))
result$Under_Sampling = data.frame(c(0.9995084373222475,0.8901876266312907))
result$SMOTE = data.frame(c(0.9994663033784401,0.9023405417267101))
result$ADASYN = data.frame(c(0.9993890578147933,0.8982438459344533))
result$GAN = data.frame(c(0.999557596696722,0.9003572630796582))
colnames(result) <- c("Non Sampling","Under Sampling","SMOTE","ADASYN","GAN")
rownames(result) <- c("ACC","AUC")
#result$index <- c("ACC","AUC")
result  = data.frame(t(result))
result
library(ggplot2)
ggplot(data = result)+
geom_point(mapping = aes(x = ACC,y = AUC,color = rownames(result)),size=7)
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::insert_image_addin()
![](/post/2019-11-25-gan-based-small-sample-augmentation_files/1.jfif)
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::insert_image_addin()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::insert_image_addin()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::insert_image_addin()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::insert_image_addin()
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
# Read data
data_csv <- read.csv("20191202_1471_CRE_46-non-CRE_49_Intensity.csv")
# arrange
if (!require(tidyverse)) install.packages('tidyverse')
library(tidyverse)
#sort data by p.value
data_csv <- arrange(data_csv,p.value)
#transpose data
name_protein <- data_csv[,1]
data <- as.data.frame(t(data_csv))
data <- data[-c(1:3),]
#data name
name_variable <- names(data)
data_name <- data.frame(name_variable,name_protein)
data_name <- as.data.frame(t(data_name))
#label CRE as factor
data$CRE <- as.factor(c(rep(1,46),rep(0,49)))
df1 = data
#classification function
pca.clf <- function(lgr = TRUE,nb = TRUE,knn = TRUE,rf = TRUE,svm = TRUE,pca_num){
#filter pca num
df = as.data.frame(df1[,c(1:pca_num)])
names(df) = names(df1[c(1:pca_num)])
df$CRE = df1$CRE
#ml model training
library(caret)
#svm
if(svm){
if (!require(e1071))install.packages('e1071')
library(e1071)
test.pred <- vector()
for(i in c(1:dim(df)[1])){
train = df[-i, ]
test  = df[i, ]
#pca processing
pca <- prcomp(~.-CRE, data=train)
train_pca <- as.data.frame(pca$x)
train_pca$CRE <- train$CRE
#Matrix multiplication
test_pca = as.data.frame(as.matrix(test[,-dim(test)[2]])%*%as.matrix(pca$rotation))
test_pca$CRE <- test$CRE
svm_model = svm(formula = CRE ~ .,data = train_pca)
test.pred[i] = as.integer(predict(svm_model, test_pca))-1
}
#result present
confus.matrix = table(test.pred,df$CRE)
if(dim(confus.matrix)[1] > 1){
num11 <- confus.matrix[2,2]
num00 <- confus.matrix[1,1]
}else{
num11 = confus.matrix[1,2]
num00 = 0
}
svm <- c("SupportVectorMachine",num11+num00,(num11+num00)/sum(confus.matrix),num11,as.integer(num00),num11/sum(confus.matrix[,2]),num00/sum(confus.matrix[,1]))
}
#rf
if(rf){
if (!require(randomForest)) install.packages('randomForest')
library(randomForest)
test.pred <- vector()
for(i in c(1:dim(df)[1])){
train = df[-i, ]
test  = df[i, ]
#pca processing
pca <- prcomp(~.-CRE, data=train)
train_pca <- as.data.frame(pca$x)
train_pca$CRE <- train$CRE
#Matrix multiplication
test_pca = as.data.frame(as.matrix(test[,-dim(test)[2]])%*%as.matrix(pca$rotation))
test_pca$CRE <- test$CRE
rf_model = randomForest(CRE~.,data=train_pca,ntree=150# num of decision Tree
)
test.pred[i] = as.integer(predict(rf_model, test_pca))-1
}
#result present
confus.matrix = table(test.pred,df$CRE)
if(dim(confus.matrix)[1] > 1){
num11 <- confus.matrix[2,2]
num00 <- confus.matrix[1,1]
}else{
num11 = confus.matrix[1,2]
num00 = 0
}
rf <- c("RandomForest",num11+num00,(num11+num00)/sum(confus.matrix),num11,as.integer(num00),num11/sum(confus.matrix[,2]),num00/sum(confus.matrix[,1]))
}
# knn
if(knn){
if (!require(class))install.packages("class")
library(class)
test.pred <- vector()
for(i in c(1:dim(df)[1])){
train = df[-i, ]
test  = df[i, ]
#pca processing
pca <- prcomp(~.-CRE, data=train)
train_pca <- as.data.frame(pca$x)
train_pca$CRE <- train$CRE
#Matrix multiplication
test_pca = as.data.frame(as.matrix(test[,-dim(test)[2]])%*%as.matrix(pca$rotation))
test_pca$CRE <- test$CRE
#pred
test.pred[i] <- knn(train = train_pca[,-length(train_pca)], test = test_pca[,-length(test_pca)], cl = train_pca[,length(train_pca)], k = 5)   # knn distance = 5
}
#result present
confus.matrix = table(test.pred,df$CRE)
if(dim(confus.matrix)[1] > 1){
num11 <- confus.matrix[2,2]
num00 <- confus.matrix[1,1]
}else{
num11 = confus.matrix[1,2]
num00 = 0
}
knn <- c("NearestNeighbors",num11+num00,(num11+num00)/sum(confus.matrix),num11,as.integer(num00),num11/sum(confus.matrix[,2]),num00/sum(confus.matrix[,1]))
}
# nb
if(nb){
test.pred <- vector()
for(i in c(1:dim(df)[1])){
train = df[-i, ]
test  = df[i, ]
#pca processing
pca <- prcomp(~.-CRE, data=train)
train_pca <- as.data.frame(pca$x)
train_pca$CRE <- train$CRE
#Matrix multiplication
test_pca = as.data.frame(as.matrix(test[,-dim(test)[2]])%*%as.matrix(pca$rotation))
test_pca$CRE <- test$CRE
#pred
nb_model=naiveBayes(CRE~., data=train_pca)
test.pred[i] = as.integer(predict(nb_model, test_pca))-1
}
#result present
confus.matrix = table(test.pred,df$CRE)
if(dim(confus.matrix)[1] > 1){
num11 <- confus.matrix[2,2]
num00 <- confus.matrix[1,1]
}else{
num11 = confus.matrix[1,2]
num00 = 0
}
nb <- c("NavieBayes",num11+num00,(num11+num00)/sum(confus.matrix),num11,as.integer(num00),num11/sum(confus.matrix[,2]),num00/sum(confus.matrix[,1]))
}
#lgr
if(lgr){
test.pred <- vector()
df$CRE = as.numeric(df$CRE)-1
#pca processing
pca <- prcomp(~.-CRE, data=train)
train_pca <- as.data.frame(pca$x)
train_pca$CRE <- train$CRE
#Matrix multiplication
test_pca = as.data.frame(as.matrix(test[,-dim(test)[2]])%*%as.matrix(pca$rotation))
test_pca$CRE <- test$CRE
#pred
for(i in c(1:dim(df)[1])){
train = df[-i, ]
test  = df[i, ]
lr_model<-glm(formula=CRE~.,data=train,family=binomial)
test.pred[i] <- ifelse(predict(lr_model, test,type = "response") > 0.5, 1, 0)
}
#result present
confus.matrix = table(test.pred,df$CRE)
if(dim(confus.matrix)[1] > 1){
num11 <- confus.matrix[2,2]
num00 <- confus.matrix[1,1]
}else{
num11 = confus.matrix[1,2]
num00 = 0
}
lgr <- c("LogisticRegression",num11+num00,(num11+num00)/sum(confus.matrix),num11,as.integer(num00),num11/sum(confus.matrix[,2]),num00/sum(confus.matrix[,1]))
}
#return results
result <- c(46,49,pca_num,lgr,nb,knn,rf,svm)
return(result)
}
a = as.data.frame(t(pca.clf(pca=1)))
for(i in c(2:25)){
b = as.data.frame(t(pca.clf(pca=i)))
a = rbind(a,b)
}
View(a)
names(a) = c("num_cre","num_non","num_pca","method","right_pred_num","acc","right_pred_cre_num","right_pred_ncre_num","right_pred_cre_acc","right_pred_ncre_acc","method","right_pred_num","acc","right_pred_cre_num","right_pred_ncre_num","right_pred_cre_acc","right_pred_ncre_acc","method","right_pred_num","acc","right_pred_cre_num","right_pred_ncre_num","right_pred_cre_acc","right_pred_ncre_acc","method","right_pred_num","acc","right_pred_cre_num","right_pred_ncre_num","right_pred_cre_acc","right_pred_ncre_acc","method","right_pred_num","acc","right_pred_cre_num","right_pred_ncre_num","right_pred_cre_acc","right_pred_ncre_acc")
write.csv(a,file = "pca_result.csv",row.names = FALSE)
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::insert_image_addin()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::insert_image_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::insert_image_addin()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
---
title: SQL Query Optimization
author: Hermit
date: '2020-01-06'
slug: sql-query-optimization
categories:
- SQL
tags:
- small-talk
---
這學期修的資管系資料庫系統期末報告，主要是建立一個有著大資料表的資料庫系統，並且針對系統下三個查詢語句，並且進行查詢句的優化，
blogdown:::insert_image_addin()
SELECT t1.code , t1.name
blogdown:::serve_site()
blogdown:::serve_site()
我們第三個查詢句為：
```{r eval = FALSE}
SELECT t1.code , t1.name
from (
(SELECT condition_table.CODE,condition_table.NAME ,condition_table."indicator" , condition_table.date1
FROM condition_table
WHERE condition_table.date1 = 20191108 AND condition_table.COND_MATCH = 1) t1
join
(SELECT CODE
FROM stock_price_data
WHERE dirction = 'increasing' AND date1 >= 20191106 AND date1 <= 20191108
HAVING COUNT(dirction)=3
GROUP BY CODE,NAME) t2
ON t1.code = t2.code
)
```
主要目的是為了查詢連日上漲且符合進場標準的股票，列出名稱、代碼、以及進場條件，在這邊我們設定是三天內皆上漲，且現在正好是滿足進場條件的股票，因此這個查詢句需要join兩個表格：股價資料以及進場條件資料
我們第三個查詢句為：
```{r eval = FALSE}
SELECT t1.code , t1.name
from (
(SELECT condition_table.CODE,condition_table.NAME ,condition_table."indicator" , condition_table.date1
FROM condition_table
WHERE condition_table.date1 = 20191108 AND condition_table.COND_MATCH = 1) t1
join
(SELECT CODE
FROM stock_price_data
WHERE dirction = 'increasing' AND date1 >= 20191106 AND date1 <= 20191108
HAVING COUNT(dirction)=3
GROUP BY CODE,NAME) t2
ON t1.code = t2.code
)
```
主要目的是為了查詢連日上漲且符合進場標準的股票，列出名稱、代碼、以及進場條件，在這邊我們設定是三天內皆上漲，且現在正好是滿足進場條件的股票，因此這個查詢句需要join兩個表格：股價資料以及進場條件資料
?
= =
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::insert_image_addin()
而目前wgan的效果未必比較好，雖然wgan的設置可以讓兩個神經網路的loss有同時下降的可能
而目前wgan的效果未必比較好，雖然wgan的設置可以讓兩個神經網路的loss有同時下降的可能，但從我們的結果論來看並不一定會有比較好的效果，也可能是wgan設定的Weight Clipping沒有比較好的定義
knitr::opts_chunk$set(echo = TRUE)
library(rvest)
link = paste0("https://www.cnyes.com/twstock/ps_historyprice/2887.htm")
price <- read_html(link)
#get the table
price_data1 <- html_nodes(price,"div.mbx.bd3")
price_data <- html_text(price_data1)
View(price_data1)
price_data
#get the table
price_data1 <- html_nodes(price,"div.tab")
price_data <- html_text(price_data1)
price_data
blogdown:::new_post_addin()
blogdown:::serve_site()
---
title: 'OCGAN Pratice: CRE Bateria data'
author: Hermit
date: '2020-02-04'
slug: ocgan-pratice-cre-bateria-data
categories:
- gan
- deep-learning
- Python
tags:
- classification
- neural network
---
這次使用之前分析過的CRE資料，來嘗試使用OCGAN，但因原先資料CRE:NON比數為46:49，為了達到不平衡的效果，因此最後採用16:49的比例，從46個CRE中取隨機16個，
blogdown:::insert_image_addin()
