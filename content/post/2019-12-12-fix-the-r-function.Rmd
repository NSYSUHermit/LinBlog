---
title: 'Fix The R Function '
author: Hermit
date: '2019-12-12'
slug: fix-the-r-function
categories:
  - machine-learning
  - R
tags:
  - classification
---
這禮拜我做的那個function執行順序上跟老師所要求的有所不同，因此這次將結果修改為老師所要的執行方式。  
原先我以為是要先將所有資料的變數進行pca轉換後再進行分類器leave one out的訓練，因此是將訓練以及測試的資料同時PCA轉換，大致流程為下圖：  
![](/post/2019-12-12-fix-the-r-function_files/1.JPG)
因此訓練資料的正交化與測試資料的正交是同時進行的，因此與老師所要求的流程上不同。   
老師是希望先將資料切分為1:ALL-1，並以ALL-1的Training Set 來進行PCA轉換、訓練分類器，最後將測試資料乘上訓練用的PCA轉換矩陣，並將其結果帶入分類器上來驗證分類預測結果，以此循環進行LOOCV，流程大致如下圖：  
![](/post/2019-12-12-fix-the-r-function_files/2.JPG)  
因此最大的差別即，PCA從迴圈外改至迴圈內，但因一個分類方法就一個迴圈，而我並未進行程式速度的優化(合併迴圈減少PCA計算量)，因此PCA將會依照方法數量來執行數次。  

另外，老師說不需要調整樣本數量，因此取消有關樣本數的函數輸入參數。  

下面是程式代碼。  


## def function
```{r,eval = FALSE}
# Read data
data_csv <- read.csv("20191202_1471_CRE_46-non-CRE_49_Intensity.csv")

# arrange
if (!require(tidyverse)) install.packages('tidyverse')
library(tidyverse)

#sort data by p.value
data_csv <- arrange(data_csv,p.value)

#transpose data
name_protein <- data_csv[,1]
data <- as.data.frame(t(data_csv))
data <- data[-c(1:3),]

#data name
name_variable <- names(data)
data_name <- data.frame(name_variable,name_protein)
data_name <- as.data.frame(t(data_name))

#label CRE as factor
data$CRE <- as.factor(c(rep(1,46),rep(0,49)))
df1 = data

#classification function
pca.clf <- function(lgr = TRUE,nb = TRUE,knn = TRUE,rf = TRUE,svm = TRUE,pca_num){
  #filter pca num
  df = as.data.frame(df1[,c(1:pca_num)])
  names(df) = names(df1[c(1:pca_num)])
  df$CRE = df1$CRE
  #ml model training
  library(caret)
  #svm
  if(svm){
    if (!require(e1071))install.packages('e1071')
    library(e1071)
    test.pred <- vector()
    for(i in c(1:dim(df)[1])){
      train = df[-i, ]
      test  = df[i, ]
      
      #pca processing
      pca <- prcomp(~.-CRE, data=train) 
      train_pca <- as.data.frame(pca$x)
      train_pca$CRE <- train$CRE 
      
      #Matrix multiplication
      test_pca = as.data.frame(as.matrix(test[,-dim(test)[2]])%*%as.matrix(pca$rotation))
      test_pca$CRE <- test$CRE 

      svm_model = svm(formula = CRE ~ .,data = train_pca)
      test.pred[i] = as.integer(predict(svm_model, test_pca))-1
      }
    #result present
    confus.matrix = table(test.pred,df$CRE)
    if(dim(confus.matrix)[1] > 1){
      num11 <- confus.matrix[2,2]
      num00 <- confus.matrix[1,1]
    }else{
      num11 = confus.matrix[1,2]
      num00 = 0
      }
    svm <- c("SupportVectorMachine",num11+num00,(num11+num00)/sum(confus.matrix),num11,as.integer(num00),num11/sum(confus.matrix[,2]),num00/sum(confus.matrix[,1]))
  }
  #rf
  if(rf){
    if (!require(randomForest)) install.packages('randomForest')
    library(randomForest)
    test.pred <- vector()
    for(i in c(1:dim(df)[1])){
      train = df[-i, ]
      test  = df[i, ]
      
      #pca processing
      pca <- prcomp(~.-CRE, data=train) 
      train_pca <- as.data.frame(pca$x)
      train_pca$CRE <- train$CRE 
      
      #Matrix multiplication
      test_pca = as.data.frame(as.matrix(test[,-dim(test)[2]])%*%as.matrix(pca$rotation))
      test_pca$CRE <- test$CRE 
      
      rf_model = randomForest(CRE~.,data=train_pca,ntree=150# num of decision Tree
                        )
      test.pred[i] = as.integer(predict(rf_model, test_pca))-1
      }
      #result present
    confus.matrix = table(test.pred,df$CRE)
    if(dim(confus.matrix)[1] > 1){
      num11 <- confus.matrix[2,2]
      num00 <- confus.matrix[1,1]
    }else{
      num11 = confus.matrix[1,2]
      num00 = 0
      }
    rf <- c("RandomForest",num11+num00,(num11+num00)/sum(confus.matrix),num11,as.integer(num00),num11/sum(confus.matrix[,2]),num00/sum(confus.matrix[,1]))
  }
  # knn
  if(knn){
    if (!require(class))install.packages("class")
    library(class)
    test.pred <- vector()
    for(i in c(1:dim(df)[1])){
      train = df[-i, ]
      test  = df[i, ]
      #pca processing
      pca <- prcomp(~.-CRE, data=train) 
      train_pca <- as.data.frame(pca$x)
      train_pca$CRE <- train$CRE 
      
      #Matrix multiplication
      test_pca = as.data.frame(as.matrix(test[,-dim(test)[2]])%*%as.matrix(pca$rotation))
      test_pca$CRE <- test$CRE 
      
      #pred
      test.pred[i] <- knn(train = train_pca[,-length(train_pca)], test = test_pca[,-length(test_pca)], cl = train_pca[,length(train_pca)], k = 5)   # knn distance = 5
      }
      #result present
    confus.matrix = table(test.pred,df$CRE)
    if(dim(confus.matrix)[1] > 1){
      num11 <- confus.matrix[2,2]
      num00 <- confus.matrix[1,1]
    }else{
      num11 = confus.matrix[1,2]
      num00 = 0
      }
    knn <- c("NearestNeighbors",num11+num00,(num11+num00)/sum(confus.matrix),num11,as.integer(num00),num11/sum(confus.matrix[,2]),num00/sum(confus.matrix[,1]))
  }
  # nb
  if(nb){
    test.pred <- vector()
    for(i in c(1:dim(df)[1])){
      train = df[-i, ]
      test  = df[i, ]
      #pca processing
      pca <- prcomp(~.-CRE, data=train) 
      train_pca <- as.data.frame(pca$x)
      train_pca$CRE <- train$CRE 
      
      #Matrix multiplication
      test_pca = as.data.frame(as.matrix(test[,-dim(test)[2]])%*%as.matrix(pca$rotation))
      test_pca$CRE <- test$CRE 
      
      #pred
      nb_model=naiveBayes(CRE~., data=train_pca)
      test.pred[i] = as.integer(predict(nb_model, test_pca))-1
      }
      #result present
    confus.matrix = table(test.pred,df$CRE)
    if(dim(confus.matrix)[1] > 1){
      num11 <- confus.matrix[2,2]
      num00 <- confus.matrix[1,1]
    }else{
      num11 = confus.matrix[1,2]
      num00 = 0
      }
     nb <- c("NavieBayes",num11+num00,(num11+num00)/sum(confus.matrix),num11,as.integer(num00),num11/sum(confus.matrix[,2]),num00/sum(confus.matrix[,1]))
  }
  #lgr
  if(lgr){
    test.pred <- vector()
    df$CRE = as.numeric(df$CRE)-1
    #pca processing
    pca <- prcomp(~.-CRE, data=train) 
    train_pca <- as.data.frame(pca$x)
    train_pca$CRE <- train$CRE 
      
    #Matrix multiplication
    test_pca = as.data.frame(as.matrix(test[,-dim(test)[2]])%*%as.matrix(pca$rotation))
    test_pca$CRE <- test$CRE 
      
    #pred
    for(i in c(1:dim(df)[1])){
      train = df[-i, ]
      test  = df[i, ]
      lr_model<-glm(formula=CRE~.,data=train,family=binomial)
      test.pred[i] <- ifelse(predict(lr_model, test,type = "response") > 0.5, 1, 0)
      }
      #result present
    confus.matrix = table(test.pred,df$CRE)
    if(dim(confus.matrix)[1] > 1){
      num11 <- confus.matrix[2,2]
      num00 <- confus.matrix[1,1]
    }else{
      num11 = confus.matrix[1,2]
      num00 = 0
      }
     lgr <- c("LogisticRegression",num11+num00,(num11+num00)/sum(confus.matrix),num11,as.integer(num00),num11/sum(confus.matrix[,2]),num00/sum(confus.matrix[,1]))
  }
  #return results
  result <- c(46,49,pca_num,lgr,nb,knn,rf,svm)
  return(result)
}
```

## present results
測試PC1至PC22，並將結果存於dataframe a。  
```{r),eval = FALSE}
a = as.data.frame(t(pca.clf(pca=1)))
for(i in c(2:25)){
  b = as.data.frame(t(pca.clf(pca=i)))
  a = rbind(a,b) 
}
```


## names columns
為dataframe命名column name
```{r,eval = FALSE}
names(a) = c("num_cre","num_non","num_pca","method","right_pred_num","acc","right_pred_cre_num","right_pred_ncre_num","right_pred_cre_acc","right_pred_ncre_acc","method","right_pred_num","acc","right_pred_cre_num","right_pred_ncre_num","right_pred_cre_acc","right_pred_ncre_acc","method","right_pred_num","acc","right_pred_cre_num","right_pred_ncre_num","right_pred_cre_acc","right_pred_ncre_acc","method","right_pred_num","acc","right_pred_cre_num","right_pred_ncre_num","right_pred_cre_acc","right_pred_ncre_acc","method","right_pred_num","acc","right_pred_cre_num","right_pred_ncre_num","right_pred_cre_acc","right_pred_ncre_acc")
```

## write csv
將結果輸出至代碼所在路徑。
```{r,eval = FALSE}
write.csv(a,file = "pca_result.csv",row.names = FALSE)
```

輸出結果如下：  
![](/post/2019-12-12-fix-the-r-function_files/3.JPG)  