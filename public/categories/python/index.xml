<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on Lin&#39;s Blog</title>
    <link>/categories/python/</link>
    <description>Recent content in Python on Lin&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Feb 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title> Compare to OCGAN &amp; SMOTE &amp; ADASYN in breast cancer data Simulation</title>
      <link>/post/2020/02/18/compare-to-ocgan-smote-adasyn-in-breast-cancer-data-simulation/</link>
      <pubDate>Tue, 18 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/02/18/compare-to-ocgan-smote-adasyn-in-breast-cancer-data-simulation/</guid>
      <description>這次我使用sklearn內建的資料集breast-cancer(原始資料來源：https://archive.ics.uci.edu/ml/</description>
    </item>
    
    <item>
      <title>CRE features selection</title>
      <link>/post/2020/02/14/cre-features-selection/</link>
      <pubDate>Fri, 14 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/02/14/cre-features-selection/</guid>
      <description>This time I will use the scikit-learn module to bulid the classifiers,and I will use the randomforest&amp;rsquo;s importance to choose the explanatory variables. Part1. Import the data and R&amp;rsquo;S randomforest importance import pandas as pd import numpy as np df = pd.read_csv(&#39;C:/Users/User/OneDrive - student.nsysu.edu.tw/Educations/NSYSU/fu_chung/bacterial/123.csv&#39;) impor = pd.read_csv(&#39;C:/Users/User/OneDrive - student.nsysu.edu.tw/Educations/NSYSU/fu_chung/bacterial - PCA/A.csv&#39;) impo = np.array(impor[&#39;names&#39;]) impo array([&#39;V994&#39;, &#39;V1428&#39;, &#39;V1426&#39;, ..., &#39;V1469&#39;, &#39;V1470&#39;, &#39;V1471&#39;], dtype=object) Part2. Classifiers Building Contain methods: svm,randomforest,navie bayes,knn,lda,qda,adaboost,logistic</description>
    </item>
    
    <item>
      <title>CRE data features selection</title>
      <link>/post/2020/02/10/cre-data-features-selection/</link>
      <pubDate>Mon, 10 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/02/10/cre-data-features-selection/</guid>
      <description>這次僅針對CRE data的模型變數選擇，主要以下面python的forward backward selection的方式進行挑選，主要方式為：將所有資料的百</description>
    </item>
    
    <item>
      <title>OCGAN Pratice: CRE Bateria data</title>
      <link>/post/2020/02/04/ocgan-pratice-cre-bateria-data/</link>
      <pubDate>Tue, 04 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/02/04/ocgan-pratice-cre-bateria-data/</guid>
      <description>這次使用之前分析過的CRE資料，來嘗試使用OCGAN，但因原先資料CRE:NON比數為46:49，為了達到不平衡的效果，因此最後採用16:4</description>
    </item>
    
    <item>
      <title>OCGAN Tuning</title>
      <link>/post/2020/01/16/ocgan-tuning/</link>
      <pubDate>Thu, 16 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/01/16/ocgan-tuning/</guid>
      <description>基本上生成樣本已經是可以達成的事情，目前就是調整gan各處的結構，如優化器、激活函數、損失函數等等，目前嘗試皆以randomforest(n</description>
    </item>
    
    <item>
      <title>WGAN Practice On Credit Card Data</title>
      <link>/post/2019/12/17/wgan-practice-on-credit-card-data/</link>
      <pubDate>Tue, 17 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/12/17/wgan-practice-on-credit-card-data/</guid>
      <description>前幾篇我有提到WGAN在訓練過程中可以改善兩個神經網路loss很難調教的問題(很常判別器的loss下降，生成器的卻一直上升，或是情況相反)，</description>
    </item>
    
    <item>
      <title>The Crawler Code in my internship.</title>
      <link>/post/2019/11/28/the-crawler-code-in-my-internship/</link>
      <pubDate>Thu, 28 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/11/28/the-crawler-code-in-my-internship/</guid>
      <description>In this summer vacation, I was become a intern engineer in a internet service company. In fact, our company is an eshops price comparison platform. Here is the website link:https://biggo.com.tw/ . They crawler the products information in different eshops like Amazon, PChome etc. Build a SQL system store the data. Then run a browser engine website to present the price comparision results. Its service area including Taiwan, Tailand, Singapore. Now</description>
    </item>
    
    <item>
      <title>GAN Sampling Versus Other Sampling Method On Credit Card Fraud Detection Data</title>
      <link>/post/2019/11/19/gan-sampling-versus-other-sampling-method-on-credit-card-fraud-detection-data/</link>
      <pubDate>Tue, 19 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/11/19/gan-sampling-versus-other-sampling-method-on-credit-card-fraud-detection-data/</guid>
      <description>這次，我將使用一個來自kaggle的不平衡數據資料(link:https://www.kaggle.com/mlg-ulb/creditca</description>
    </item>
    
    <item>
      <title>Practice in GAN with One Class Learning</title>
      <link>/post/2019/11/14/practice-in-gan-with-one-class-learning/</link>
      <pubDate>Thu, 14 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/11/14/practice-in-gan-with-one-class-learning/</guid>
      <description>這次我將使用先前東海大學大數據競賽的初賽資料，也就是熱成化加工的數據資料，而該資料中一共有8類，我將資料的第5與8類挑選出來，並僅取3筆第5</description>
    </item>
    
    <item>
      <title>GAN with One Class Learning</title>
      <link>/post/2019/11/09/gan-with-one-class-learning/</link>
      <pubDate>Sat, 09 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/11/09/gan-with-one-class-learning/</guid>
      <description>先前幾次我嘗試使用生成對抗網路產生一系列資料，但我們知道GAN的訓練很難調整，除非將生成資料直接拿去訓練比照結果，否則很難知道這次生成樣本的</description>
    </item>
    
    <item>
      <title>One Class Learning</title>
      <link>/post/2019/10/02/one-class-learning/</link>
      <pubDate>Wed, 02 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/10/02/one-class-learning/</guid>
      <description>在資料探勘中，異常檢測:anomaly detection對不符合預期模式或資料集中其他專案的專案、事件或觀測值的辨識。 通常異常專案會轉變成銀</description>
    </item>
    
    <item>
      <title>How to compose a python(or R) script on linux commander.</title>
      <link>/post/2019/08/27/how-to-compose-a-python-or-r-script-on-linux-commander/</link>
      <pubDate>Tue, 27 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/08/27/how-to-compose-a-python-or-r-script-on-linux-commander/</guid>
      <description>In this article I will show how to bulid a script file on your location. And how to compose the script on Python (or R). You should bulid the Python script on your virtual environment if you want to use the keras CUDA.
You should enter your server at begining.
Rstep 1. Set up the file location:You can key “dir” to check all files on your location.</description>
    </item>
    
    <item>
      <title>THU Preliminary by Neural Network</title>
      <link>/post/2019/08/22/thu-preliminary-by-neural-network/</link>
      <pubDate>Thu, 22 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/08/22/thu-preliminary-by-neural-network/</guid>
      <description>先前剛看完齋藤康毅的深度學習架構，因此最近正在學習使用keras架立神經網路模型，範例檔案都是使用mnist手寫資料，正在練習時突然想到先前</description>
    </item>
    
    <item>
      <title>MLB playoff prediction with SVM &amp; Randomforest</title>
      <link>/post/2019/08/19/mlb-playoff-prediction/</link>
      <pubDate>Mon, 19 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/08/19/mlb-playoff-prediction/</guid>
      <description>In the same theme,MLB. I will show how to use Python to train a randomforest and SVM classifier. Our target is predicting whether the team will enter the next year playoff or not. Since the playoff qualification depends on the same year&amp;rsquo;s season game win rate. If we predict the same year playoff is pointless. So I make the variable &amp;ldquo;palyoff&amp;rdquo; to &amp;ldquo;next year playoff&amp;rdquo;. I will use the module</description>
    </item>
    
    <item>
      <title>Using pandas to craw MLB team data</title>
      <link>/post/2019/07/27/using-pandas-to-craw-mlb-team-data/</link>
      <pubDate>Sat, 27 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/07/27/using-pandas-to-craw-mlb-team-data/</guid>
      <description>MLB 球隊資料 爬蟲 這次參與工研院資料科學的課程，課程中分配的小組必須進行一個完整資料分析的報告，題目自訂。 因為球類的open data相對完整，基</description>
    </item>
    
  </channel>
</rss>