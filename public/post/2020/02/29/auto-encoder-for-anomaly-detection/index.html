<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <title>Auto Encoder for Anomaly Detection | Lin&#39;s Blog</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    <link href="//cdn.bootcss.com/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">

  </head>

  <body class="page">
    <nav class="header">
      <div class="banner">
<a href="/" class="text">
&Lfr;&Ifr;&Nfr;'&Sfr; &Bfr;&Lfr;&Ofr;&Gfr;
</a>
</div>

      <div class="head-meta">
      
        <span><a href="/">&larr; Back to Home</a></span>
        <span class="date">2020-02-29</span>
        
        
        
          
        
        
        
        <span><a href="https://github.com/yihui/hugo-xmag/edit/master/exampleSite/content/post/2020-02-29-auto-encoder-for-anomaly-detection.Rmd">Edit this page &rarr;</a></span>
        
        
      
      </div>
    </nav>

<div class="container">
<article>
<div class="article-meta">

  <div class="categories">
  
    <a href="/categories/deep-learning">deep-learning</a>
  
     &hercon; <a href="/categories/python">Python</a>
  
     &hercon; <a href="/categories/machine-learning">machine-learning</a>
  
  </div>

  <h1><span class="title">Auto Encoder for Anomaly Detection</span></h1>

  
  <h3 class="author">Hermit
</h3>
  

  
  <p>Tags: <a href="/tags/neural-network">neural network</a>
  </p>
  
  

</div>



<main>



<p>這禮拜在撰寫論文的時候，因為有一段需要更詳細說明所謂的Anomaly Detection，因而發現了一個也可以進行相同工作的方法-“Auto Encoder”，且他號稱有著更佳的分類效果，因此就看了一些介紹此方法的文章以及實作，下面我將使用breast cancer data的前一百筆當作練習範本，嘗試建立一個Auto Encoder for Anomaly Detection。</p>
<div id="what-is-the-auto-encoder" class="section level1">
<h1>1.What is the Auto Encoder?</h1>
<p>Autoencoder是一種無監督式學習模型。本質上它使用了一個神經網絡來產生一個高維輸入的低維表示。 Autoencoder與主成分分析PCA類似，但是Autoencoder在使用非線性激活函數時克服了PCA線性的限制。</p>
<p>Autoencoder包含兩個主要的部分，encoder（編碼器）和 decoder（解碼器）。 Encoder的作用是用來發現給定數據的壓縮表示，decoder是用來重建原始輸入。在訓練時，decoder 強迫 autoencoder 選擇最有信息量的特徵，最終保存在壓縮表示中。最終壓縮後的表示就在中間的coder層當中。</p>
<p>以下圖為例，原始數據的維度是10，encoder和decoder分別有兩層，中間的coder共有3個節點，也就是說原始數據被降到了只有3維。 Decoder根據降維後的數據再重建原始數據，重新得到10維的輸出。從Input到Ouptut的這個過程中，autoencoder實際上也起到了降噪的作用。<br />
<img src="/post/2020-02-29-auto-encoder-for-anomaly-detection_files/1.png" /></p>
<p>而AutoEncoder的內部構造，說白了就是把輸入資料，通過數層的神經網路並輸出一份接近的資料。聽起來就是複製而已，但典型的AE還會有內部表示層(Internal Representation)，透過對一些維度限制、或加入雜訊到輸入資料，讓整個AE的結構更加複雜，整個流程就不是只有「複製輸入到輸出」，這樣單純而已了，其中最重要的就是輸出的數量(神經元)要跟輸入一樣。</p>
<p>另外Autoencoder要如何做到無監督異常檢測?異常檢測(anomaly detection)通常分為有監督和無監督兩種情形。在無監督的情況下，我們沒有異常樣本用來學習，而算法的基本上假設是異常點服從不同的分佈。根據正常數據訓練出來的Autoencoder，能夠將正常樣本重建還原，但是卻無法將異於正常分佈的數據點較好地還原，導致還原誤差較大。</p>
<p>如果樣本的特徵都是數值變量，我們可以用MSE或者MAE作為還原誤差。</p>
</div>
<div id="import-data-standard-scaler" class="section level1">
<h1>2.Import Data &amp; Standard Scaler</h1>
<p>這裡讀取之前用過的breast cancer資料，且抓取前100筆資料當作sample，想透過Autoencoder來檢測樣本是否為乳癌患者。</p>
<pre class="python"><code>import pandas as pd
import numpy as np
from sklearn import datasets
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

#d = pd.read_csv(&#39;C:/Users/User/OneDrive - student.nsysu.edu.tw/Documents/dataset/creditcard.csv&#39;)
df = datasets.load_breast_cancer()
x = pd.DataFrame(df[&#39;data&#39;],columns = df[&#39;feature_names&#39;])[0:100]

x = pd.DataFrame(StandardScaler().fit_transform(x))

y = pd.DataFrame(df[&#39;target&#39;],columns = [&#39;targets_names&#39;])[0:100]
d = pd.concat([x,y],axis = 1)

#show the data of labels
%matplotlib inline
by_fraud = y.groupby(&#39;targets_names&#39;)
by_fraud.size().plot(kind = &#39;bar&#39;)</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1d953959c88&gt;</code></pre>
<p>有症狀vs無症狀樣本比例:<br />
35:65</p>
<p><img src="/post/2020-02-29-auto-encoder-for-anomaly-detection_files/output_1_1.png" /></p>
<p>引入套件</p>
<pre class="python"><code>import pandas as pd
import numpy as np
import pickle
import matplotlib.pyplot as plt
plt.style.use(&#39;seaborn&#39;)
import tensorflow as tf
import seaborn as sns
from sklearn.model_selection import train_test_split
from keras.models import Model, load_model
from keras.layers import Input, Dense
from keras.callbacks import ModelCheckpoint
from keras import regularizers
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_curve, auc, precision_recall_curve</code></pre>
</div>
<div id="model-setting" class="section level1">
<h1>3.Model Setting</h1>
<p>我將資料裡未得病的一半當作訓練集，其餘的一半未得病以及35名病患皆當作測試集。</p>
<pre class="python"><code># 查看樣本比例
num_nonfraud = np.sum(d[&#39;targets_names&#39;] == 0)
num_fraud = np.sum(d[&#39;targets_names&#39;] == 1)
plt.bar([&#39;Positive&#39;, &#39;Negative&#39;], [num_fraud, num_nonfraud], color=&#39;dodgerblue&#39;)
plt.show()
data = d

# 提取負樣本，並且按照1:1切成訓練集和測試集
mask = (data[&#39;targets_names&#39;] == 0)
X_train, X_test = train_test_split(data[mask], test_size=0.5, random_state=920)
X_train = X_train.drop([&#39;targets_names&#39;], axis=1).values
X_test = X_test.drop([&#39;targets_names&#39;], axis=1).values

# 提取所有正樣本，作為測試集的一部分
X_fraud = data[~mask].drop([&#39;targets_names&#39;], axis=1).values

# 設置Autoencoder的參數
# 隱藏層節點數分別為16，8，8，16
# epoch為50，batch size為32
input_dim = X_train.shape[1]
encoding_dim = 16
num_epoch = 250
batch_size = 32

input_layer = Input(shape=(input_dim, ))
encoder = Dense(encoding_dim, activation=&quot;tanh&quot;,
                activity_regularizer=regularizers.l1(10e-5))(input_layer)
encoder = Dense(int(encoding_dim / 2), activation=&quot;relu&quot;)(encoder)
decoder = Dense(int(encoding_dim / 2), activation=&#39;tanh&#39;)(encoder)
decoder = Dense(input_dim, activation=&#39;relu&#39;)(decoder)
autoencoder = Model(inputs=input_layer, outputs=decoder)
autoencoder.compile(optimizer=&#39;adam&#39;,loss=&#39;mean_squared_error&#39;,metrics=[&#39;mae&#39;])

# 模型保存為hermit_model，並開始訓練模型
checkpointer = ModelCheckpoint(filepath=&quot;hermit_model&quot;,verbose=0,save_best_only=True)
history = autoencoder.fit(X_train, X_train,
                          epochs=num_epoch,
                          batch_size=batch_size,
                          shuffle=True,
                          validation_data=(X_test, X_test),
                          verbose=1, 
                          callbacks=[checkpointer]).history

# 畫出損失函數曲線
plt.figure(figsize=(14, 5))
plt.subplot(121)
plt.plot(history[&#39;loss&#39;], c=&#39;dodgerblue&#39;, lw=3)
plt.plot(history[&#39;val_loss&#39;], c=&#39;coral&#39;, lw=3)
plt.title(&#39;model loss&#39;)
plt.ylabel(&#39;mse&#39;); plt.xlabel(&#39;epoch&#39;)
plt.legend([&#39;train&#39;, &#39;test&#39;], loc=&#39;upper right&#39;)

plt.subplot(122)
plt.plot(history[&#39;mean_absolute_error&#39;], c=&#39;dodgerblue&#39;, lw=3)
plt.plot(history[&#39;val_mean_absolute_error&#39;], c=&#39;coral&#39;, lw=3)
plt.title(&#39;model mae&#39;)
plt.ylabel(&#39;mae&#39;); plt.xlabel(&#39;epoch&#39;)
plt.legend([&#39;train&#39;, &#39;test&#39;], loc=&#39;upper right&#39;);</code></pre>
<pre><code>Train on 32 samples, validate on 33 samples
Epoch 1/250
32/32 [==============================] - 1s 41ms/step - loss: 1.1633 - mean_absolute_error: 0.7738 - val_loss: 0.7262 - val_mean_absolute_error: 0.6667
Epoch 2/250
32/32 [==============================] - 0s 93us/step - loss: 1.1595 - mean_absolute_error: 0.7725 - val_loss: 0.7242 - val_mean_absolute_error: 0.6658
Epoch 3/250
32/32 [==============================] - 0s 93us/step - loss: 1.1550 - mean_absolute_error: 0.7709 - val_loss: 0.7222 - val_mean_absolute_error: 0.6649
Epoch 4/250
32/32 [==============================] - 0s 62us/step - loss: 1.1502 - mean_absolute_error: 0.7692 - val_loss: 0.7201 - val_mean_absolute_error: 0.6639
Epoch 5/250
32/32 [==============================] - 0s 94us/step - loss: 1.1453 - mean_absolute_error: 0.7674 - val_loss: 0.7179 - val_mean_absolute_error: 0.6629
Epoch 6/250
32/32 [==============================] - 0s 93us/step - loss: 1.1402 - mean_absolute_error: 0.7657 - val_loss: 0.7155 - val_mean_absolute_error: 0.6619
Epoch 7/250
32/32 [==============================] - 0s 95us/step - loss: 1.1352 - mean_absolute_error: 0.7639 - val_loss: 0.7131 - val_mean_absolute_error: 0.6608
Epoch 8/250
32/32 [==============================] - 0s 94us/step - loss: 1.1303 - mean_absolute_error: 0.7622 - val_loss: 0.7107 - val_mean_absolute_error: 0.6597
Epoch 9/250
32/32 [==============================] - 0s 94us/step - loss: 1.1254 - mean_absolute_error: 0.7605 - val_loss: 0.7083 - val_mean_absolute_error: 0.6586
Epoch 10/250
32/32 [==============================] - 0s 94us/step - loss: 1.1203 - mean_absolute_error: 0.7588 - val_loss: 0.7061 - val_mean_absolute_error: 0.6576
Epoch 11/250
32/32 [==============================] - 0s 93us/step - loss: 1.1150 - mean_absolute_error: 0.7570 - val_loss: 0.7038 - val_mean_absolute_error: 0.6565
Epoch 12/250
32/32 [==============================] - 0s 93us/step - loss: 1.1095 - mean_absolute_error: 0.7552 - val_loss: 0.7013 - val_mean_absolute_error: 0.6554
Epoch 13/250
32/32 [==============================] - 0s 94us/step - loss: 1.1039 - mean_absolute_error: 0.7534 - val_loss: 0.6988 - val_mean_absolute_error: 0.6542
Epoch 14/250
32/32 [==============================] - 0s 125us/step - loss: 1.0982 - mean_absolute_error: 0.7516 - val_loss: 0.6961 - val_mean_absolute_error: 0.6530
Epoch 15/250
32/32 [==============================] - 0s 94us/step - loss: 1.0925 - mean_absolute_error: 0.7497 - val_loss: 0.6933 - val_mean_absolute_error: 0.6517
Epoch 16/250
32/32 [==============================] - 0s 93us/step - loss: 1.0868 - mean_absolute_error: 0.7479 - val_loss: 0.6904 - val_mean_absolute_error: 0.6504
Epoch 17/250
32/32 [==============================] - 0s 94us/step - loss: 1.0809 - mean_absolute_error: 0.7459 - val_loss: 0.6875 - val_mean_absolute_error: 0.6491
Epoch 18/250
32/32 [==============================] - 0s 94us/step - loss: 1.0748 - mean_absolute_error: 0.7439 - val_loss: 0.6845 - val_mean_absolute_error: 0.6478
Epoch 19/250
32/32 [==============================] - 0s 93us/step - loss: 1.0687 - mean_absolute_error: 0.7419 - val_loss: 0.6817 - val_mean_absolute_error: 0.6465
Epoch 20/250
32/32 [==============================] - 0s 125us/step - loss: 1.0624 - mean_absolute_error: 0.7402 - val_loss: 0.6789 - val_mean_absolute_error: 0.6454
Epoch 21/250
32/32 [==============================] - 0s 62us/step - loss: 1.0563 - mean_absolute_error: 0.7384 - val_loss: 0.6762 - val_mean_absolute_error: 0.6442
Epoch 22/250
32/32 [==============================] - 0s 62us/step - loss: 1.0504 - mean_absolute_error: 0.7367 - val_loss: 0.6735 - val_mean_absolute_error: 0.6431
Epoch 23/250
32/32 [==============================] - 0s 94us/step - loss: 1.0445 - mean_absolute_error: 0.7350 - val_loss: 0.6710 - val_mean_absolute_error: 0.6421
Epoch 24/250
32/32 [==============================] - 0s 62us/step - loss: 1.0387 - mean_absolute_error: 0.7332 - val_loss: 0.6685 - val_mean_absolute_error: 0.6410
Epoch 25/250
32/32 [==============================] - 0s 94us/step - loss: 1.0328 - mean_absolute_error: 0.7314 - val_loss: 0.6661 - val_mean_absolute_error: 0.6399
Epoch 26/250
32/32 [==============================] - 0s 94us/step - loss: 1.0271 - mean_absolute_error: 0.7297 - val_loss: 0.6637 - val_mean_absolute_error: 0.6388
Epoch 27/250
32/32 [==============================] - 0s 94us/step - loss: 1.0216 - mean_absolute_error: 0.7279 - val_loss: 0.6613 - val_mean_absolute_error: 0.6376
Epoch 28/250
32/32 [==============================] - 0s 125us/step - loss: 1.0161 - mean_absolute_error: 0.7262 - val_loss: 0.6591 - val_mean_absolute_error: 0.6365
Epoch 29/250
32/32 [==============================] - 0s 94us/step - loss: 1.0108 - mean_absolute_error: 0.7244 - val_loss: 0.6568 - val_mean_absolute_error: 0.6354
Epoch 30/250
32/32 [==============================] - 0s 94us/step - loss: 1.0057 - mean_absolute_error: 0.7227 - val_loss: 0.6546 - val_mean_absolute_error: 0.6343
Epoch 31/250
32/32 [==============================] - 0s 94us/step - loss: 1.0006 - mean_absolute_error: 0.7210 - val_loss: 0.6525 - val_mean_absolute_error: 0.6331
Epoch 32/250
32/32 [==============================] - 0s 93us/step - loss: 0.9955 - mean_absolute_error: 0.7194 - val_loss: 0.6504 - val_mean_absolute_error: 0.6320
Epoch 33/250
32/32 [==============================] - 0s 93us/step - loss: 0.9906 - mean_absolute_error: 0.7179 - val_loss: 0.6483 - val_mean_absolute_error: 0.6310
Epoch 34/250
32/32 [==============================] - 0s 124us/step - loss: 0.9858 - mean_absolute_error: 0.7164 - val_loss: 0.6463 - val_mean_absolute_error: 0.6299
Epoch 35/250
32/32 [==============================] - 0s 93us/step - loss: 0.9813 - mean_absolute_error: 0.7149 - val_loss: 0.6444 - val_mean_absolute_error: 0.6289
Epoch 36/250
32/32 [==============================] - 0s 94us/step - loss: 0.9769 - mean_absolute_error: 0.7136 - val_loss: 0.6424 - val_mean_absolute_error: 0.6279
Epoch 37/250
32/32 [==============================] - 0s 93us/step - loss: 0.9726 - mean_absolute_error: 0.7122 - val_loss: 0.6405 - val_mean_absolute_error: 0.6268
Epoch 38/250
32/32 [==============================] - 0s 93us/step - loss: 0.9684 - mean_absolute_error: 0.7109 - val_loss: 0.6386 - val_mean_absolute_error: 0.6258
Epoch 39/250
32/32 [==============================] - 0s 93us/step - loss: 0.9643 - mean_absolute_error: 0.7095 - val_loss: 0.6368 - val_mean_absolute_error: 0.6247
Epoch 40/250
32/32 [==============================] - 0s 94us/step - loss: 0.9602 - mean_absolute_error: 0.7082 - val_loss: 0.6350 - val_mean_absolute_error: 0.6237
Epoch 41/250
32/32 [==============================] - 0s 94us/step - loss: 0.9561 - mean_absolute_error: 0.7068 - val_loss: 0.6333 - val_mean_absolute_error: 0.6226
Epoch 42/250
32/32 [==============================] - 0s 93us/step - loss: 0.9521 - mean_absolute_error: 0.7054 - val_loss: 0.6315 - val_mean_absolute_error: 0.6216
Epoch 43/250
32/32 [==============================] - 0s 94us/step - loss: 0.9482 - mean_absolute_error: 0.7041 - val_loss: 0.6297 - val_mean_absolute_error: 0.6206
Epoch 44/250
32/32 [==============================] - 0s 94us/step - loss: 0.9444 - mean_absolute_error: 0.7028 - val_loss: 0.6280 - val_mean_absolute_error: 0.6196
Epoch 45/250
32/32 [==============================] - 0s 94us/step - loss: 0.9405 - mean_absolute_error: 0.7015 - val_loss: 0.6263 - val_mean_absolute_error: 0.6187
Epoch 46/250
32/32 [==============================] - 0s 94us/step - loss: 0.9367 - mean_absolute_error: 0.7001 - val_loss: 0.6246 - val_mean_absolute_error: 0.6177
Epoch 47/250
32/32 [==============================] - 0s 94us/step - loss: 0.9329 - mean_absolute_error: 0.6988 - val_loss: 0.6229 - val_mean_absolute_error: 0.6168
Epoch 48/250
32/32 [==============================] - 0s 93us/step - loss: 0.9291 - mean_absolute_error: 0.6975 - val_loss: 0.6212 - val_mean_absolute_error: 0.6158
Epoch 49/250
32/32 [==============================] - 0s 94us/step - loss: 0.9253 - mean_absolute_error: 0.6961 - val_loss: 0.6194 - val_mean_absolute_error: 0.6148
Epoch 50/250
32/32 [==============================] - 0s 125us/step - loss: 0.9215 - mean_absolute_error: 0.6948 - val_loss: 0.6176 - val_mean_absolute_error: 0.6138</code></pre>
<p>此圖為訓練的損失值情況：<br />
<img src="/post/2020-02-29-auto-encoder-for-anomaly-detection_files/output_3_2.png" /></p>
</div>
<div id="results-for-mse-mae-both" class="section level1">
<h1>4.Results for MSE &amp; MAE &amp; both</h1>
<p>我在這將會使用兩種方式計算誤差，並且使用兩種方式，設置自定義閥值(threshold)，並用該閥值的結果來判定是否為異常資料並加以標記，最終計算AUC加以比較異常檢測效果。</p>
<pre class="python"><code># 讀取模型
autoencoder = load_model(&#39;hermit_model&#39;)

# 利用訓練好的autoencoder重建測試集
pred_test = autoencoder.predict(X_test)
pred_fraud = autoencoder.predict(X_fraud)

# 計算還原誤差MSE和MAE
markers = [&#39;o&#39;, &#39;^&#39;]
markers = [&#39;o&#39;, &#39;^&#39;]
colors = [&#39;dodgerblue&#39;, &#39;coral&#39;]
labels = [&#39;Negative&#39;, &#39;Positive&#39;]

plt.figure(figsize=(14, 5))
plt.subplot(121)
for flag in [1, 0]:
    temp = mse_df[mse_df[&#39;targets_names&#39;] == flag]
    plt.scatter(temp.index, 
                temp[&#39;MAE&#39;],  
                alpha=0.7, 
                marker=markers[flag], 
                c=colors[flag], 
                label=labels[flag])
plt.title(&#39;Reconstruction MAE&#39;)
plt.ylabel(&#39;Reconstruction MAE&#39;); plt.xlabel(&#39;Index&#39;)
threshold = mse_df[&#39;MAE&#39;].min()+0.8*mse_df[&#39;MAE&#39;].std()
plt.plot([0,len(y)],[threshold,threshold])
plt.subplot(122)

for flag in [1, 0]:
    temp = mse_df[mse_df[&#39;targets_names&#39;] == flag]
    plt.scatter(temp.index, 
                temp[&#39;MSE&#39;],  
                alpha=0.7, 
                marker=markers[flag], 
                c=colors[flag], 
                label=labels[flag])
plt.legend(loc=[1, 0], fontsize=12); plt.title(&#39;Reconstruction MSE&#39;)
threshold = mse_df[&#39;MSE&#39;].min()+mse_df[&#39;MSE&#39;].std()
plt.plot([0,len(y)],[threshold,threshold])
plt.ylabel(&#39;Reconstruction MSE&#39;); plt.xlabel(&#39;Index&#39;)
plt.show()</code></pre>
<p>此圖左為使用MAE當作參考值的結果，線段為自定義的閥值；右圖則為MSE的結果：<br />
<img src="/post/2020-02-29-auto-encoder-for-anomaly-detection_files/output_4_0.png" /></p>
<p>用MSE的threshold的結果計算auc等統計量值</p>
<pre class="python"><code>from sklearn import metrics

threshold = mse_df[&#39;MSE&#39;].min()+mse_df[&#39;MSE&#39;].std()
mse_df[&#39;targets_names&#39;]
mse_df[&#39;mse_y_pred&#39;] = [1 if e &gt; threshold else 0 for e in mse_df[&#39;MSE&#39;]]
mse_df[&#39;targets_names&#39;].describe()
test_auc = metrics.roc_auc_score(mse_df[&#39;targets_names&#39;], mse_df[&#39;mse_y_pred&#39;])
print (test_auc)</code></pre>
<pre><code>0.693939393939394</code></pre>
<p>用MAE的threshold的結果分類，計算auc等統計量值</p>
<pre class="python"><code>from sklearn import metrics

threshold = mse_df[&#39;MAE&#39;].min()+0.8*mse_df[&#39;MAE&#39;].std()
mse_df[&#39;targets_names&#39;]
mse_df[&#39;mae_y_pred&#39;] = [1 if e &gt; threshold else 0 for e in mse_df[&#39;MAE&#39;]]
mse_df[&#39;targets_names&#39;].describe()
test_auc = metrics.roc_auc_score(mse_df[&#39;targets_names&#39;], mse_df[&#39;mae_y_pred&#39;])
print (test_auc)</code></pre>
<pre><code>0.548051948051948</code></pre>
<p>MSE分類結果的confusion matrix</p>
<pre class="python"><code>from sklearn.metrics import confusion_matrix
LABELS = [&quot;Negative&quot;, &quot;Positive&quot;]
conf_matrix = confusion_matrix(mse_df[&#39;targets_names&#39;], mse_df[&#39;mse_y_pred&#39;])
plt.figure(figsize=(12, 12))
sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=&quot;d&quot;);
plt.title(&quot;Confusion matrix&quot;)
plt.ylabel(&#39;True class&#39;)
plt.xlabel(&#39;Predicted class&#39;)
plt.show()</code></pre>
<p><img src="/post/2020-02-29-auto-encoder-for-anomaly-detection_files/output_8_0.png" /></p>
<p>MAE分類結果的confusion matrix</p>
<pre class="python"><code>from sklearn.metrics import confusion_matrix
LABELS = [&quot;Negative&quot;, &quot;Positive&quot;]
conf_matrix = confusion_matrix(mse_df[&#39;targets_names&#39;], mse_df[&#39;mae_y_pred&#39;])
plt.figure(figsize=(12, 12))
sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=&quot;d&quot;);
plt.title(&quot;Confusion matrix&quot;)
plt.ylabel(&#39;True class&#39;)
plt.xlabel(&#39;Predicted class&#39;)
plt.show()</code></pre>
<p><img src="/post/2020-02-29-auto-encoder-for-anomaly-detection_files/output_9_0.png" /></p>
<p>畫出Precision-Recall曲線與ROC曲線</p>
<pre class="python"><code># 畫出Precision-Recall曲線
plt.figure(figsize=(14, 6))
for i, metric in enumerate([&#39;MAE&#39;, &#39;MSE&#39;]):
    plt.subplot(1, 2, i+1)
    precision, recall, _ = precision_recall_curve(mse_df[&#39;targets_names&#39;], mse_df[metric])
    pr_auc = auc(recall, precision)
    plt.title(&#39;Precision-Recall curve based on %s\nAUC = %0.2f&#39;%(metric, pr_auc))
    plt.plot(recall[:-2], precision[:-2], c=&#39;coral&#39;, lw=4)
    plt.xlabel(&#39;Recall&#39;); plt.ylabel(&#39;Precision&#39;)
plt.show()

# 畫出ROC曲線
plt.figure(figsize=(14, 6))
for i, metric in enumerate([&#39;MAE&#39;, &#39;MSE&#39;]):
    plt.subplot(1, 2, i+1)
    fpr, tpr, _ = roc_curve(mse_df[&#39;targets_names&#39;], mse_df[metric])
    roc_auc = auc(fpr, tpr)
    plt.title(&#39;Receiver Operating Characteristic based on %s\nAUC = %0.2f&#39;%(metric, roc_auc))
    plt.plot(fpr, tpr, c=&#39;coral&#39;, lw=4)
    plt.plot([0,1],[0,1], c=&#39;dodgerblue&#39;, ls=&#39;--&#39;)
    plt.ylabel(&#39;TPR&#39;); plt.xlabel(&#39;FPR&#39;)
plt.show()
</code></pre>
<p><img src="/post/2020-02-29-auto-encoder-for-anomaly-detection_files/output_10_0.png" /></p>
<p><img src="/post/2020-02-29-auto-encoder-for-anomaly-detection_files/output_10_1.png" /></p>
<p>下面則為同時參考兩者MSE&amp;MAE結果的分類情形：</p>
<pre class="python"><code>#用MSE&amp;MAE的threshold的結果分類，計算auc以及acc等統計量值
from sklearn import metrics

mse_threshold = mse_df[&#39;MSE&#39;].min()+mse_df[&#39;MSE&#39;].std()
mae_threshold = mse_df[&#39;MAE&#39;].min()+0.8*mse_df[&#39;MAE&#39;].std()
mse_df[&#39;msae_y_pred&#39;] = 0
for i in range(len(mse_df[&#39;mse_y_pred&#39;])):
    if mse_df[&#39;mse_y_pred&#39;][i] == mse_df[&#39;mae_y_pred&#39;][i]:
        mse_df[&#39;msae_y_pred&#39;][i] = 1
mse_df[&#39;targets_names&#39;].describe()
test_auc = metrics.roc_auc_score(mse_df[&#39;targets_names&#39;], mse_df[&#39;msae_y_pred&#39;])
print (test_auc)</code></pre>
<pre><code>0.645887445887446


C:\Users\User\Anaconda3\envs\Tensorflow-gpu\lib\site-packages\ipykernel_launcher.py:9: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  if __name__ == &#39;__main__&#39;:</code></pre>
<pre class="python"><code>mse_df.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
targets_names
</th>
<th>
MSE
</th>
<th>
MAE
</th>
<th>
y_pred
</th>
<th>
mse_y_pred
</th>
<th>
mae_y_pred
</th>
<th>
msae_y_pred
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
1.303796
</td>
<td>
1.009276
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
</tr>
<tr>
<th>
1
</th>
<td>
0
</td>
<td>
0.651611
</td>
<td>
0.642855
</td>
<td>
1
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
</tr>
<tr>
<th>
2
</th>
<td>
1
</td>
<td>
0.732258
</td>
<td>
0.836285
</td>
<td>
1
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
</tr>
<tr>
<th>
3
</th>
<td>
0
</td>
<td>
0.440141
</td>
<td>
0.563211
</td>
<td>
1
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
</tr>
<tr>
<th>
4
</th>
<td>
0
</td>
<td>
0.502424
</td>
<td>
0.569734
</td>
<td>
1
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
</tr>
</tbody>
</table>
</div>
<pre class="python"><code># 畫出MSE、MAE散點圖
markers = [&#39;o&#39;, &#39;^&#39;]
colors = [&#39;dodgerblue&#39;, &#39;coral&#39;]
labels = [&#39;Negative&#39;, &#39;Positive&#39;]

plt.figure(figsize=(10, 5))
for flag in [1, 0]:
    temp = mse_df[mse_df[&#39;targets_names&#39;] == flag]
    plt.scatter(temp[&#39;MAE&#39;], 
                temp[&#39;MSE&#39;],  
                alpha=0.7, 
                marker=markers[flag], 
                c=colors[flag], 
                label=labels[flag])
plt.legend(loc=[1, 0])
plt.plot([mse_threshold,mse_threshold],[0,mse_df[&#39;MSE&#39;].max()])
plt.plot([0,mse_df[&#39;MAE&#39;].max()],[mae_threshold,mae_threshold])
plt.ylabel(&#39;Reconstruction RMSE&#39;); plt.xlabel(&#39;Reconstruction MAE&#39;)
plt.show()</code></pre>
<p><img src="/post/2020-02-29-auto-encoder-for-anomaly-detection_files/output_13_0.png" /></p>
<pre class="python"><code>from sklearn.metrics import confusion_matrix
LABELS = [&quot;Negative&quot;, &quot;Positive&quot;]
conf_matrix = confusion_matrix(mse_df[&#39;targets_names&#39;], mse_df[&#39;msae_y_pred&#39;])
plt.figure(figsize=(12, 12))
sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=&quot;d&quot;);
plt.title(&quot;Confusion matrix&quot;)
plt.ylabel(&#39;True class&#39;)
plt.xlabel(&#39;Predicted class&#39;)
plt.show()</code></pre>
<p><img src="/post/2020-02-29-auto-encoder-for-anomaly-detection_files/output_14_0.png" /></p>
</div>

</main>


















<nav class="post-nav">
  <span class="nav-prev"></span>
  <span class="nav-next"><a href="/post/2020/02/25/compare-to-ocgan-smote-adasyn-in-cre-data-simulation/">Compare to OCGAN &amp; SMOTE &amp; ADASYN in CRE data Simulation &rarr;</a></span>
</nav>



</article>
</div>

<script async src="//yihui.name/js/center-img.js"></script>

<footer>

<div class="footer">
  <ul class="menu">
    
    <li><a href="/"><span data-hover="Home">Home</span></a></li>
    
    <li><a href="/categories/"><span data-hover="Categories">Categories</span></a></li>
    
    <li><a href="/tags/"><span data-hover="Tags">Tags</span></a></li>
    
    <li><a href="/about/"><span data-hover="Blogdown">Blogdown</span></a></li>
    
  </ul>
  
  <div class="copyright">&copy; <a href="/about1/">Lin</a> | <a href="https://github.com/NSYSUHermit">Github</a> | <a href="https://rpubs.com/JupiterHenry">Rpubs</a></div>
  
</div>
</footer>


<script src="//yihui.name/js/math-code.js"></script>
<script async src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>



<script src="//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.12.0/languages/r.min.js"></script>
<script>
hljs.configure({languages: []});
hljs.initHighlightingOnLoad();
</script>




</body>
</html>

