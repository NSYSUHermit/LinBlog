<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>classification on Lin&#39;s Blog</title>
    <link>/tags/classification/</link>
    <description>Recent content in classification on Lin&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Feb 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/classification/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title> Compare to OCGAN &amp; SMOTE &amp; ADASYN in breast cancer data Simulation</title>
      <link>/post/2020/02/18/compare-to-ocgan-smote-adasyn-in-breast-cancer-data-simulation/</link>
      <pubDate>Tue, 18 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/02/18/compare-to-ocgan-smote-adasyn-in-breast-cancer-data-simulation/</guid>
      <description>這次我使用sklearn內建的資料集breast-cancer(原始資料來源：https://archive.ics.uci.edu/ml/</description>
    </item>
    
    <item>
      <title>CRE features selection</title>
      <link>/post/2020/02/14/cre-features-selection/</link>
      <pubDate>Fri, 14 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/02/14/cre-features-selection/</guid>
      <description>This time I will use the scikit-learn module to bulid the classifiers,and I will use the randomforest&amp;rsquo;s importance to choose the explanatory variables. Part1. Import the data and R&amp;rsquo;S randomforest importance import pandas as pd import numpy as np df = pd.read_csv(&#39;C:/Users/User/OneDrive - student.nsysu.edu.tw/Educations/NSYSU/fu_chung/bacterial/123.csv&#39;) impor = pd.read_csv(&#39;C:/Users/User/OneDrive - student.nsysu.edu.tw/Educations/NSYSU/fu_chung/bacterial - PCA/A.csv&#39;) impo = np.array(impor[&#39;names&#39;]) impo array([&#39;V994&#39;, &#39;V1428&#39;, &#39;V1426&#39;, ..., &#39;V1469&#39;, &#39;V1470&#39;, &#39;V1471&#39;], dtype=object) Part2. Classifiers Building Contain methods: svm,randomforest,navie bayes,knn,lda,qda,adaboost,logistic</description>
    </item>
    
    <item>
      <title>CRE data features selection</title>
      <link>/post/2020/02/10/cre-data-features-selection/</link>
      <pubDate>Mon, 10 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/02/10/cre-data-features-selection/</guid>
      <description>這次僅針對CRE data的模型變數選擇，主要以下面python的forward backward selection的方式進行挑選，主要方式為：將所有資料的百</description>
    </item>
    
    <item>
      <title>OCGAN Pratice: CRE Bateria data</title>
      <link>/post/2020/02/04/ocgan-pratice-cre-bateria-data/</link>
      <pubDate>Tue, 04 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/02/04/ocgan-pratice-cre-bateria-data/</guid>
      <description>這次使用之前分析過的CRE資料，來嘗試使用OCGAN，但因原先資料CRE:NON比數為46:49，為了達到不平衡的效果，因此最後採用16:4</description>
    </item>
    
    <item>
      <title>OCGAN Tuning</title>
      <link>/post/2020/01/16/ocgan-tuning/</link>
      <pubDate>Thu, 16 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/01/16/ocgan-tuning/</guid>
      <description>基本上生成樣本已經是可以達成的事情，目前就是調整gan各處的結構，如優化器、激活函數、損失函數等等，目前嘗試皆以randomforest(n</description>
    </item>
    
    <item>
      <title>Paper Review [LOTUS:Logistic Tree with Unbiased Selection]</title>
      <link>/post/2019/12/26/paper-review-lotus-logistic-tree-with-unbiased-selection/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/12/26/paper-review-lotus-logistic-tree-with-unbiased-selection/</guid>
      <description>因為修統計書報的關係，這次也被分配要報告一個章節，雖然那本書是工具書取向，但是發現該作者有在2004年寫了一篇有關logistic regre</description>
    </item>
    
    <item>
      <title>WGAN Practice On Credit Card Data</title>
      <link>/post/2019/12/17/wgan-practice-on-credit-card-data/</link>
      <pubDate>Tue, 17 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/12/17/wgan-practice-on-credit-card-data/</guid>
      <description>前幾篇我有提到WGAN在訓練過程中可以改善兩個神經網路loss很難調教的問題(很常判別器的loss下降，生成器的卻一直上升，或是情況相反)，</description>
    </item>
    
    <item>
      <title>Fix The R Function </title>
      <link>/post/2019/12/12/fix-the-r-function/</link>
      <pubDate>Thu, 12 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/12/12/fix-the-r-function/</guid>
      <description>這禮拜我做的那個function執行順序上跟老師所要求的有所不同，因此這次將結果修改為老師所要的執行方式。 原先我以為是要先將所有資料的變數進</description>
    </item>
    
    <item>
      <title>The R Function Definition for CRE Bacteria Data Analysis</title>
      <link>/post/2019/12/10/the-r-function-definition-for-cre-bacteria-data-analysis/</link>
      <pubDate>Tue, 10 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/12/10/the-r-function-definition-for-cre-bacteria-data-analysis/</guid>
      <description>這次是跟上次使用相同的資料，只是變成要定義一個規定格式的function，剛好上次的code裡面logistic regression的分類器</description>
    </item>
    
    <item>
      <title>GAN Based Small Sample Augmentation</title>
      <link>/post/2019/11/25/gan-based-small-sample-augmentation/</link>
      <pubDate>Mon, 25 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/11/25/gan-based-small-sample-augmentation/</guid>
      <description>I read some paper about GAN for generate synthetic sample data. Then I find a paper it’s framework works similar with my one-class-GAN. So I want to record the paper’s marrows this time. There is the paper resource link: https://www.sciencedirect.com/science/article/abs/pii/S0925231219309257?dgcid=rss_sd_all In this paper, we propose an approach based on a generative adversarial network (GAN) combined with a deep neural network (DNN).</description>
    </item>
    
    <item>
      <title>GAN Sampling Versus Other Sampling Method On Credit Card Fraud Detection Data</title>
      <link>/post/2019/11/19/gan-sampling-versus-other-sampling-method-on-credit-card-fraud-detection-data/</link>
      <pubDate>Tue, 19 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/11/19/gan-sampling-versus-other-sampling-method-on-credit-card-fraud-detection-data/</guid>
      <description>這次，我將使用一個來自kaggle的不平衡數據資料(link:https://www.kaggle.com/mlg-ulb/creditca</description>
    </item>
    
    <item>
      <title>Practice in GAN with One Class Learning</title>
      <link>/post/2019/11/14/practice-in-gan-with-one-class-learning/</link>
      <pubDate>Thu, 14 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/11/14/practice-in-gan-with-one-class-learning/</guid>
      <description>這次我將使用先前東海大學大數據競賽的初賽資料，也就是熱成化加工的數據資料，而該資料中一共有8類，我將資料的第5與8類挑選出來，並僅取3筆第5</description>
    </item>
    
    <item>
      <title>Using GAN to generate some non image data with CRE bateria data</title>
      <link>/post/2019/11/06/using-gan-to-generate-some-non-image-data-with-cre-bateria-data/</link>
      <pubDate>Wed, 06 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/11/06/using-gan-to-generate-some-non-image-data-with-cre-bateria-data/</guid>
      <description>這次我將修改前次的生成對抗網路，希望能夠調整為一個自動生成樣本的神經網路。我這次將使用以前曾經使用過的CRE Bacteria data(https://hermitlin.netlify.com/post/2019/04/24/cre-bacteria-data-analysis/ )。 我先建立一個簡單的分類模</description>
    </item>
    
    <item>
      <title>One Class Learning</title>
      <link>/post/2019/10/02/one-class-learning/</link>
      <pubDate>Wed, 02 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/10/02/one-class-learning/</guid>
      <description>在資料探勘中，異常檢測:anomaly detection對不符合預期模式或資料集中其他專案的專案、事件或觀測值的辨識。 通常異常專案會轉變成銀</description>
    </item>
    
    <item>
      <title>THU Preliminary by Neural Network</title>
      <link>/post/2019/08/22/thu-preliminary-by-neural-network/</link>
      <pubDate>Thu, 22 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/08/22/thu-preliminary-by-neural-network/</guid>
      <description>先前剛看完齋藤康毅的深度學習架構，因此最近正在學習使用keras架立神經網路模型，範例檔案都是使用mnist手寫資料，正在練習時突然想到先前</description>
    </item>
    
    <item>
      <title>MLB playoff prediction with SVM &amp; Randomforest</title>
      <link>/post/2019/08/19/mlb-playoff-prediction/</link>
      <pubDate>Mon, 19 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/08/19/mlb-playoff-prediction/</guid>
      <description>In the same theme,MLB. I will show how to use Python to train a randomforest and SVM classifier. Our target is predicting whether the team will enter the next year playoff or not. Since the playoff qualification depends on the same year&amp;rsquo;s season game win rate. If we predict the same year playoff is pointless. So I make the variable &amp;ldquo;palyoff&amp;rdquo; to &amp;ldquo;next year playoff&amp;rdquo;. I will use the module</description>
    </item>
    
    <item>
      <title>2019 THU Big Data Preliminary</title>
      <link>/post/2019/08/11/2019-thu-big-data-preliminary/</link>
      <pubDate>Sun, 11 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/08/11/2019-thu-big-data-preliminary/</guid>
      <description>I participated in the 2019 Donghae University Big Data Competition. In this article, I will show waht kind of the problem we should do and how I finish the work. ※There is contest Description: 1.訓練數據(用於建立模型) 此數據為建模用，數據為熱壓爐成化加</description>
    </item>
    
    <item>
      <title>CRE Bacteria Data Analysis</title>
      <link>/post/2019/04/24/cre-bacteria-data-analysis/</link>
      <pubDate>Wed, 24 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/04/24/cre-bacteria-data-analysis/</guid>
      <description>在這個資料中，我們有兩種細菌。前面的46個觀察值是CRE，後面的49個則不是。 我們希望將資料分類為是否為 CRE。Peak是蛋白質的名稱，而P</description>
    </item>
    
  </channel>
</rss>