<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>small-talk on Lin&#39;s Blog</title>
    <link>/tags/small-talk/</link>
    <description>Recent content in small-talk on Lin&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 26 Dec 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/small-talk/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Paper Review [LOTUS:Logistic Tree with Unbiased Selection]</title>
      <link>/post/2019/12/26/paper-review-lotus-logistic-tree-with-unbiased-selection/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/12/26/paper-review-lotus-logistic-tree-with-unbiased-selection/</guid>
      <description>因為修統計書報的關係，這次也被分配要報告一個章節，雖然那本書是工具書取向，但是發現該作者有在2004年寫了一篇有關logistic regre</description>
    </item>
    
    <item>
      <title>Paper Review [OCGAN: One-class Novelty Detection Using GANs with Constrained Latent Representations]</title>
      <link>/post/2019/12/23/paper-review-ocgan-one-class-novelty-detection-using-gans-with-constrained-latent-representations/</link>
      <pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/12/23/paper-review-ocgan-one-class-novelty-detection-using-gans-with-constrained-latent-representations/</guid>
      <description>這禮拜看完一篇有關生成對抗網路與One Class Learning 結合的論文(Source Link:https://arxiv.org/abs/1903.08550) ，其名稱為&amp;lt;&amp;gt;，因此主要方法與我目前在用的內容有關。 作者提出</description>
    </item>
    
    <item>
      <title>GAN Based Small Sample Augmentation</title>
      <link>/post/2019/11/25/gan-based-small-sample-augmentation/</link>
      <pubDate>Mon, 25 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/11/25/gan-based-small-sample-augmentation/</guid>
      <description>I read some paper about GAN for generate synthetic sample data. Then I find a paper it’s framework works similar with my one-class-GAN. So I want to record the paper’s marrows this time. There is the paper resource link: https://www.sciencedirect.com/science/article/abs/pii/S0925231219309257?dgcid=rss_sd_all In this paper, we propose an approach based on a generative adversarial network (GAN) combined with a deep neural network (DNN).</description>
    </item>
    
    <item>
      <title>GAN with One Class Learning</title>
      <link>/post/2019/11/09/gan-with-one-class-learning/</link>
      <pubDate>Sat, 09 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/11/09/gan-with-one-class-learning/</guid>
      <description>先前幾次我嘗試使用生成對抗網路產生一系列資料，但我們知道GAN的訓練很難調整，除非將生成資料直接拿去訓練比照結果，否則很難知道這次生成樣本的</description>
    </item>
    
    <item>
      <title>Generative Adversarial Network Practice</title>
      <link>/post/2019/10/23/generative-adversarial-network-practice/</link>
      <pubDate>Wed, 23 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/10/23/generative-adversarial-network-practice/</guid>
      <description>由Goodfellow等人在2014年推出的生成對抗神經網路適用於學習圖像空間VAE的替代方法。藉由強制讓聲稱ˊ圖像與真實圖片在統計上幾乎無</description>
    </item>
    
    <item>
      <title>Dropout </title>
      <link>/post/2019/10/16/dropout/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/10/16/dropout/</guid>
      <description>Drop 是由Geoff Hinton與多倫多大學的學生所開發的神經網路常規化技術之一。神經網路層的丟棄法，主要是在訓練期間隨機丟棄layer的一些輸</description>
    </item>
    
    <item>
      <title>Imbalanced Data Binary Classification</title>
      <link>/post/2019/09/25/imbalanced-data-binary-classification/</link>
      <pubDate>Wed, 25 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/09/25/imbalanced-data-binary-classification/</guid>
      <description>不平衡資料 (Imbalanced Data)是很常見於結構化資料的情境之一。比如說我們有一筆保險客戶的資料，有非常多的客戶基本資料(如:居住地、學歷等等)，以及一</description>
    </item>
    
    <item>
      <title>How to compose a python(or R) script on linux commander.</title>
      <link>/post/2019/08/27/how-to-compose-a-python-or-r-script-on-linux-commander/</link>
      <pubDate>Tue, 27 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/08/27/how-to-compose-a-python-or-r-script-on-linux-commander/</guid>
      <description>In this article I will show how to bulid a script file on your location. And how to compose the script on Python (or R). You should bulid the Python script on your virtual environment if you want to use the keras CUDA.
You should enter your server at begining.
Rstep 1. Set up the file location:You can key “dir” to check all files on your location.</description>
    </item>
    
    <item>
      <title>What is deep learning</title>
      <link>/post/2019/08/20/what-is-deep-learning/</link>
      <pubDate>Tue, 20 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/08/20/what-is-deep-learning/</guid>
      <description>最近拜讀Keras之父-Francois Chollet所撰寫的deep learning with python。 因此想撰寫一些讀後心得筆記，以留日後自己參考。 What is Deep</description>
    </item>
    
    <item>
      <title>Data Analysis Run-Down </title>
      <link>/post/2019/06/23/data-analysis-run-down/</link>
      <pubDate>Sun, 23 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/06/23/data-analysis-run-down/</guid>
      <description>日前看到一份有關資料分析流程以及方法的圖片，但因未提及結構化資料以及時間序列等，因此我將它們增加到表上，以此來釐清各分析方法的順序。 (此表不</description>
    </item>
    
  </channel>
</rss>